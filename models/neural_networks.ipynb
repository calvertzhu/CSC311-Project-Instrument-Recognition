{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0af23fb",
   "metadata": {},
   "source": [
    "# Imports/setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fab98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c4e593",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc99cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add models directory to path\n",
    "sys.path.append(str(Path.cwd() / 'models'))\n",
    "from crnn_model import create_crnn_model, CRNNConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab275e8d",
   "metadata": {},
   "source": [
    "# Loading datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca623938",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IRMASDataset(Dataset): # Adapted from PyTorch docs: https://docs.pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
    "    def __init__(self, data_file, label_file):\n",
    "        self.data = torch.from_numpy(np.load(data_file))\n",
    "        self.labels = torch.from_numpy(np.load(label_file))\n",
    "    def __len__(self):\n",
    "        return self.labels.size(dim=0)\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.index_select(self.data, 0, torch.tensor([idx])), torch.index_select(self.labels, 0, torch.tensor([idx])).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fb95c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = IRMASDataset(\"X_train.npy\", \"y_train.npy\")\n",
    "val_set = IRMASDataset(\"X_val.npy\", \"y_val.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ad2f3b",
   "metadata": {},
   "source": [
    "# Train loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc289ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, model_name, num_epochs, batch_size, lr): # Adapted from PyTorch docs: https://docs.pytorch.org/tutorials/beginner/introyt/trainingyt.html\n",
    "    train_dataloader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "    val_dataloader = DataLoader(val_set, batch_size=batch_size, shuffle=True)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    train_losses, val_losses = [], []\n",
    "    best_loss = 100000.0\n",
    "    for epoch in range(num_epochs): #TODO: calculate accuracy\n",
    "        train_loss, val_loss = 0.0, 0.0\n",
    "        print(\"Epoch: {}\".format(epoch+1))\n",
    "        c = 0\n",
    "        model.train(True)\n",
    "        for i, data in enumerate(train_dataloader): # Train\n",
    "            c += 1\n",
    "            inputs, labels = data\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        train_loss /= c\n",
    "        train_losses.append(train_loss)\n",
    "        c = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(val_dataloader): # Validation\n",
    "                c += 1\n",
    "                inputs, labels = data\n",
    "                outputs = model(inputs)\n",
    "                loss = loss_fn(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "            val_loss /= c\n",
    "            val_losses.append(val_loss)\n",
    "        print(\"Train loss: {}, val loss: {}\".format(train_loss, val_loss))\n",
    "        if val_loss < best_loss:\n",
    "            print(\"New best val loss!\")\n",
    "            best_loss = val_loss\n",
    "            model_path = \"saved_models/{}_{}\".format(model_name, epoch+1)\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    return train_losses, val_losses\n",
    "\n",
    "def test(model): #TODO\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa7d256",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cba8807",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaselineNN(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(in_features=128*128, out_features=128)\n",
    "        self.linear2 = nn.Linear(in_features=128, out_features=32)\n",
    "        self.linear3 = nn.Linear(in_features=32, out_features=11)\n",
    "    def forward(self, x_raw):\n",
    "        x = x_raw.view(-1, 128*128)\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        y = self.linear3(x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07b709b",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = BaselineNN()\n",
    "baseline_train_loss, baseline_val_loss = train(model=baseline, model_name=\"baseline\", num_epochs=20, batch_size=64, lr=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0027f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrimaryNN(nn.Module): #TODO: FINISH BUILDING; THIS IS A PLACEHOLDER\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=3, kernel_size=3, stride=1, padding=0)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.linear1 = nn.Linear(in_features=63*63*3, out_features=11)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        y = self.linear1(x.view(-1, 63*63*3))\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7fc12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "primary = PrimaryNN()\n",
    "primary_train_loss, primary_val_loss = train(model=primary, model_name=\"primary\", num_epochs=20, batch_size=64, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0ca356",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "VGG-style CNN for Music Instrument Recognition\n",
    "Based on VGG architecture adapted for mel spectrogram input.\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "class VGGBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    VGG Block: Multiple convolutional layers followed by max pooling.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, num_conv_layers=2, use_batch_norm=True):\n",
    "        super(VGGBlock, self).__init__()\n",
    "        \n",
    "        layers = []\n",
    "        for i in range(num_conv_layers):\n",
    "            if i == 0:\n",
    "                layers.append(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1))\n",
    "            else:\n",
    "                layers.append(nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1))\n",
    "            \n",
    "            if use_batch_norm:\n",
    "                layers.append(nn.BatchNorm2d(out_channels))\n",
    "            \n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "        \n",
    "        self.conv_block = nn.Sequential(*layers)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv_block(x)\n",
    "        x = self.maxpool(x)\n",
    "        return x\n",
    "\n",
    "class VGGCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    VGG-style CNN for multi-label music instrument classification.\n",
    "    \n",
    "    Architecture:\n",
    "    - VGG blocks with increasing channel sizes\n",
    "    - Global average pooling\n",
    "    - Dense classification layers\n",
    "    - Multi-label output with sigmoid\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 input_channels=1,\n",
    "                 num_classes=11,\n",
    "                 vgg_config='A',  # 'A', 'B', 'C', 'D', 'E'\n",
    "                 use_batch_norm=True,\n",
    "                 dropout_rate=0.5):\n",
    "        \"\"\"\n",
    "        Initialize VGG CNN model.\n",
    "        \n",
    "        Args:\n",
    "            input_channels: Number of input channels (1 for mel spectrograms)\n",
    "            num_classes: Number of instrument classes (11 for IRMAS)\n",
    "            vgg_config: VGG configuration ('A', 'B', 'C', 'D', 'E')\n",
    "            use_batch_norm: Whether to use batch normalization\n",
    "            dropout_rate: Dropout rate for regularization\n",
    "        \"\"\"\n",
    "        super(VGGCNN, self).__init__()\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        self.use_batch_norm = use_batch_norm\n",
    "        \n",
    "        # VGG configurations (channels per block)\n",
    "        vgg_configs = {\n",
    "            'A': [64, 128, 256, 512, 512],      # VGG-11\n",
    "            'B': [64, 128, 256, 512, 512],      # VGG-13\n",
    "            'C': [64, 128, 256, 512, 512],      # VGG-16\n",
    "            'D': [64, 128, 256, 512, 512],      # VGG-16\n",
    "            'E': [64, 128, 256, 512, 512]       # VGG-19\n",
    "        }\n",
    "        \n",
    "        # Number of conv layers per block\n",
    "        conv_layers_per_block = {\n",
    "            'A': [1, 1, 2, 2, 2],  # VGG-11\n",
    "            'B': [2, 2, 2, 2, 2],  # VGG-13\n",
    "            'C': [2, 2, 3, 3, 3],  # VGG-16\n",
    "            'D': [2, 2, 3, 3, 3],  # VGG-16\n",
    "            'E': [2, 2, 4, 4, 4]   # VGG-19\n",
    "        }\n",
    "        \n",
    "        channels = vgg_configs[vgg_config]\n",
    "        conv_layers = conv_layers_per_block[vgg_config]\n",
    "        \n",
    "        # VGG Blocks\n",
    "        self.vgg_blocks = nn.ModuleList()\n",
    "        in_channels = input_channels\n",
    "        \n",
    "        for i, (out_channels, num_conv) in enumerate(zip(channels, conv_layers)):\n",
    "            block = VGGBlock(in_channels, out_channels, num_conv, use_batch_norm)\n",
    "            self.vgg_blocks.append(block)\n",
    "            in_channels = out_channels\n",
    "        \n",
    "        # Calculate feature map size after VGG blocks\n",
    "        # Input: (batch, 1, 128, 128)\n",
    "        # After 5 blocks with pool_size=2: (batch, 512, 4, 4)\n",
    "        self.feature_size = 128 // (2 ** len(channels))  # 4\n",
    "        self.feature_channels = channels[-1]  # 512\n",
    "        \n",
    "        # Global Average Pooling\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        \n",
    "        # Classification layers\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(self.feature_channels, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(256, num_classes),\n",
    "            nn.Sigmoid()  # Multi-label classification\n",
    "        )\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._initialize_weights()\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize model weights.\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass through VGG CNN.\n",
    "        \n",
    "        Args:\n",
    "            x: Input tensor of shape (batch_size, 1, 128, 128)\n",
    "            \n",
    "        Returns:\n",
    "            Output tensor of shape (batch_size, num_classes) with sigmoid activations\n",
    "        \"\"\"\n",
    "        # VGG feature extraction\n",
    "        for vgg_block in self.vgg_blocks:\n",
    "            x = vgg_block(x)\n",
    "        \n",
    "        # Global average pooling\n",
    "        x = self.global_avg_pool(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        \n",
    "        # Classification\n",
    "        output = self.classifier(x)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def get_feature_maps(self, x):\n",
    "        \"\"\"\n",
    "        Get intermediate feature maps for visualization.\n",
    "        \n",
    "        Args:\n",
    "            x: Input tensor\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary of feature maps at different layers\n",
    "        \"\"\"\n",
    "        feature_maps = {}\n",
    "        \n",
    "        for i, vgg_block in enumerate(self.vgg_blocks):\n",
    "            x = vgg_block(x)\n",
    "            feature_maps[f'vgg_block_{i+1}'] = x.clone()\n",
    "        \n",
    "        return feature_maps\n",
    "\n",
    "class VGGConfig:\n",
    "    \"\"\"Configuration class for VGG CNN model.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.input_channels = 1\n",
    "        self.num_classes = 11\n",
    "        self.vgg_config = 'C'  # VGG-16 style\n",
    "        self.use_batch_norm = True\n",
    "        self.dropout_rate = 0.5\n",
    "        \n",
    "        # Training parameters\n",
    "        self.batch_size = 32\n",
    "        self.learning_rate = 0.001\n",
    "        self.num_epochs = 50\n",
    "        self.weight_decay = 1e-4\n",
    "        \n",
    "    def get_model(self):\n",
    "        \"\"\"Create VGG CNN model with current configuration.\"\"\"\n",
    "        return VGGCNN(\n",
    "            input_channels=self.input_channels,\n",
    "            num_classes=self.num_classes,\n",
    "            vgg_config=self.vgg_config,\n",
    "            use_batch_norm=self.use_batch_norm,\n",
    "            dropout_rate=self.dropout_rate\n",
    "        )\n",
    "\n",
    "def create_vgg_model(config=None):\n",
    "    \"\"\"\n",
    "    Factory function to create VGG CNN model.\n",
    "    \n",
    "    Args:\n",
    "        config: VGGConfig object or None for default config\n",
    "        \n",
    "    Returns:\n",
    "        VGGCNN model instance\n",
    "    \"\"\"\n",
    "    if config is None:\n",
    "        config = VGGConfig()\n",
    "    \n",
    "    return config.get_model()\n",
    "\n",
    "# Example usage and testing\n",
    "if __name__ == \"__main__\":\n",
    "    # Test different VGG configurations\n",
    "    configs = ['A', 'B', 'C', 'D', 'E']\n",
    "    \n",
    "    for config_name in configs:\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Testing VGG-{config_name}\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        # Create model\n",
    "        config = VGGConfig()\n",
    "        config.vgg_config = config_name\n",
    "        model = create_vgg_model(config)\n",
    "        \n",
    "        # Create dummy input\n",
    "        batch_size = 4\n",
    "        x = torch.randn(batch_size, 1, 128, 128)\n",
    "        \n",
    "        # Forward pass\n",
    "        output = model(x)\n",
    "        \n",
    "        print(f\"Input shape: {x.shape}\")\n",
    "        print(f\"Output shape: {output.shape}\")\n",
    "        print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "        \n",
    "        # Test feature maps\n",
    "        feature_maps = model.get_feature_maps(x)\n",
    "        for name, feature_map in feature_maps.items():\n",
    "            print(f\"{name}: {feature_map.shape}\")\n",
    "        \n",
    "        print(f\"Output range: [{output.min():.3f}, {output.max():.3f}] (should be [0,1] for sigmoid)\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5537cec5",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f63afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.arange(1, len(baseline_train_loss)+1, 1, dtype=int), baseline_train_loss, label=\"Train loss\")\n",
    "plt.scatter(np.arange(1, len(baseline_val_loss)+1, 1, dtype=int), baseline_val_loss, label=\"Validation loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Cross-Entropy Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Train and Validation Loss Curves for Baseline Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0d2e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.arange(1, len(primary_train_loss)+1, 1, dtype=int), primary_train_loss, label=\"Train loss\")\n",
    "plt.scatter(np.arange(1, len(primary_val_loss)+1, 1, dtype=int), primary_val_loss, label=\"Validation loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Cross-Entropy Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Train and Validation Loss Curves for Primary Model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
